{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will be my GAN model used to create semi-realistic face images using the celeb A dataset.  First I will import all of the relevant libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "from torchvision import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I will create a seed for this torch model in order to have reproducibility for the model.  We will also use deterministic algorithms to true as well to again ensure reproducibility of the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manualSeed = 999 # Random choice for reproducing same results\n",
    "print(\"Random Seed: \", manualSeed) # Print out the seed \n",
    "random.seed(manualSeed) # Set the seed \n",
    "torch.manual_seed(manualSeed) # Set the seed in pytorch\n",
    "torch.use_deterministic_algorithms(True) # Turn on the deterministic algorithms "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will setup the hyperparameters for the model.  These include the dataset directory path, the number of workers for the dataloader, the batch size for training, the size of the images.  We also set the number of input channels for the model (3 for colour images), the latent vector size for the generator input, the feature map sizes for the generator and the discriminator.  The number of epochs or training cycles, the learning rate of the model, the Beta1 paramentere for the Adam optimiser and the number of available GPU's "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataroot = './CelebA' # Root directory for dataset\n",
    "workers = 2 # Number of workers for dataloader\n",
    "batch_size = 128 # Batch size during training\n",
    "image_size = 64 # Spatial size of training images. All images will be resized to this. #   size using a transformer.\n",
    "nc = 3 # Number of channels in the training images. For color images this is 3\n",
    "nz = 100 # Size of z latent vector (i.e. size of generator input)\n",
    "ngf = 64 # Size of feature maps in generator\n",
    "ndf = 64 # Size of feature maps in discriminator\n",
    "num_epochs = 5 # Number of training epochs, arbitrary choice mainly for time \n",
    "lr = 0.0002 # Learning rate for optimizers, we want to avoid overshooting \n",
    "beta1 = 0.5 # Beta1 hyperparameter for Adam optimizers\n",
    "ngpu = 1 # Number of GPUs available. Use 0 for CPU mode."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
